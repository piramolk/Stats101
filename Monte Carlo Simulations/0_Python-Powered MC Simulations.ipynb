{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a85ab4e",
   "metadata": {},
   "source": [
    "# About\n",
    "* Date created: 23 Nov 2021\n",
    "* Ref: https://towardsdatascience.com/python-powered-monte-carlo-simulations-fc3c71b5b83f\n",
    "\n",
    "Objective\n",
    "* be able to implement simple MC simulation using scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2929ec1",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "664d52ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from scipy.stats import qmc    # quasi-Monte Carlo for latin hypercube sampling\n",
    "from scipy.stats import mstats \n",
    "from scipy import stats as stats\n",
    "from scipy.stats import rv_continuous\n",
    "import scipy.optimize as opt\n",
    "\n",
    "from scipy.stats import norm, weibull_min, beta\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a1deb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ksN = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a153d0",
   "metadata": {},
   "source": [
    "# 1. Theory Primer\n",
    "\n",
    "## What are Monte-carlo simulations?\n",
    "* The Monte-Carlo(MC) method is a simulation technique that constructs probability distributions for the output variables of a model in which some of the input arguments are random variables\n",
    "* MC simulation is based on repeated random sampling and the underlying concept of MC is to use <b> randomness </b> to solve problems that may be deterministic in principle\n",
    "* It is a popular techniques to draw inferences about a population without knowing the true underlying population distribution. \n",
    "    * * The MC method is sometimes called a multiple probability simulation technique because it integrates multiple random variables whose combined effects cannot easily be described by a closed-form equation.\n",
    "        * The MC method was invented in the late 1940s by John von Neumann and Stanislaw Ułam while they were working at the Los Alamos Laboratory. They hit a dead-end when they tried to compute neutron collisions by applying deterministic methods.\n",
    "* Monte Carlo has 3 main usages: \n",
    "    * estimate parameters or statistical measures, \n",
    "    * examine the properties of the estimates, \n",
    "    * approximate integrals\n",
    "    \n",
    "* One of the underlying ideas behind MC is that: as we use more samples, our answers should increasingly become more accurate\n",
    "    * Intuitively this makes sense. When flipping a coin for Heads or Tails, with a larger number of total flips we are more likely to approach the true distribution\n",
    "\n",
    "### Example of MC simulation problem\n",
    "*  An enterprise means to simulate the future success of a new product and builds the simulation model as follows:\n",
    "    * the expected sales volume, v, as a random variable that follows a beta-PERT distribution, derived from a 3-point-estimate;\n",
    "    * the price p of the product will be subject to negotiations — some customers will be in a position to claim volume discounts or early payment discounts; the planners decide to model the uncertainty about the average price the company will realize as a normal random variable around a mean of 20 and a standard deviation of 2;\n",
    "    * The raw material costs, m, of the product will be subject to upcoming supplier price increases, to be estimated by another normal distribution;\n",
    "    * The model should provide multiple outcomes: revenues, profit, total cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9fad20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fc203c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5071f778",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb4f2d1d",
   "metadata": {},
   "source": [
    "# 2. Monte Carlo Estimation\n",
    "* Monte Carlo uses the Law of Large Numbers (LLN) to come up with an estimate for a population parameter using simulated values. \n",
    "* Law of Large Numbers\n",
    "    * Suppose we have a set {X1,X2,X3....,Xn}, and they are all independent random variables with the same underlying distribution -> independent, identically distributed (i.i.d.), where all X's have the same mean and standard deviation\n",
    "    * As the sample size grows, the probability that the average of all X’s is equal to the mean μ is equal to 1.\n",
    "* Consequently, the idea behind Monte Carlo estimation is that when we obtain an estimate for a parameter a large number of times, let’s say M = 10000 times, then the mean of these estimates will form a Monte Carlo unbiased estimate for that parameter.\n",
    "\n",
    "# Monte-Carlo Estimation: Python Implementation\n",
    "* Let’s say we want to estimate a causal effect between two variables, pair of independent and dependent variables and we have some idea about possible values of intercept alpha and slope parameter beta.\n",
    "* We can randomly sample from normal distribution to generate error terms, dependent and independent variable values. * Then we can estimate the coefficient of beta, beta_hat, and repeat this process until M = 10000 times.\n",
    "* By the LLN, the sample mean of these 10000 beta_hats will be an unbiased estimate for the true beta. That is:\n",
    "\n",
    "$$\n",
    "    Y = \\alpha + \\beta X + \\epsilon\\\\\n",
    "    \\hat{\\beta}_{MC} = \\frac{1}{N} \\sum_{i=1}^{N}\\ \\hat{\\beta}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74c4afa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "np.random.seed(2021)\n",
    "\n",
    "mu = 0\n",
    "sigma = 1\n",
    "n = 100\n",
    "\n",
    "# Assume some population parameters\n",
    "alpha = np.repeat(0.5,n)\n",
    "beta = 1.5\n",
    "\n",
    "def MC_ESTIMATION_SLOPE(M):\n",
    "    MC_BETAS = []\n",
    "    MC_SAMPLES = {}\n",
    "    \n",
    "    for i in range(M):\n",
    "        #random sampling from normal distribution to get error terms\n",
    "        e = np.random.normal(mu,sigma,n)\n",
    "        \n",
    "        #generate independent variable by making sure variance_X is larger than variance_error\n",
    "        X = 9* np.random.normal(mu,sigma,n)\n",
    "        \n",
    "        #population distribution using the assumed parameter values alpha and beta\n",
    "        Y = (alpha + beta * X + e)\n",
    "        \n",
    "        # run OLS regression to get slope parameters\n",
    "        model = sm.OLS(Y.reshape((-1, 1)), X.reshape((-1, 1)))\n",
    "        ols_result = model.fit()\n",
    "        coeff = ols_result.params\n",
    "        \n",
    "        MC_SAMPLES[i] = Y\n",
    "        MC_BETAS.append(coeff)\n",
    "        \n",
    "    MC_BETA_HATS = np.array(MC_BETAS).flatten()\n",
    "    return(MC_SAMPLES,MC_BETA_HATS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e5c88a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "MC_SAMPLES, MC_BETA_HATS = MC_ESTIMATION_SLOPE(M = 10000)\n",
    "beta_hat_MC = np.mean(MC_BETA_HATS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e079905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.49450864, 1.47494779, 1.50035304, ..., 1.50746915, 1.49457376,\n",
       "       1.49608805])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MC_BETA_HATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9759c8ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5002180550943296"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_hat_MC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b579a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
